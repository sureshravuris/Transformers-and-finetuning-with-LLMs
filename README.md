# Assignment: Transformers and Fine-Tuning with LLMs

## Overview
This assignment explores the implementation and fine-tuning of transformers and large language models (LLMs). It involves two primary tasks: implementing **NanoGPT** from scratch and conducting the **"Textbooks Are All You Need"** case study with your own data. All deliverables, including code, medium articles, presentations, and artifacts, are to be completed by **December 1 at 11:59 PM**.

---

## Assignment Tasks

### Task A: Implement NanoGPT from Scratch
#### Description:
- Recreate the **NanoGPT** model from scratch using **PyTorch** in a modular format.
- Debug the code to match the caliber of the original Colab notebook.

#### Requirements:
1. **Code Implementation:**
   - Modular and well-documented implementation in Colab.
   - Debugging techniques demonstrated to ensure functionality.

2. **Training Task:**
   - Train the model on a book of your choice (different from Shakespeare's works as used in the original NanoGPT example).
   - Provide input data, model checkpoints, and generated outputs.

3. **Medium Article:**
   - Write an article explaining the code sections in depth.
   - Include detailed discussions on the architecture, implementation, and challenges.

4. **Presentation:**
   - Create a 10-minute presentation explaining the code and process step by step.

#### Resources:
- [NanoGPT Colab Notebook](https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing)
- [YouTube Video](https://www.youtube.com/watch?v=kCc8FmEb1nY&t=18s)
- [Presentation Template](https://docs.google.com/presentation/d/1fk8QlODYkBTTH4ftw8M7Sw_tmhJa8KB97s7dYP6s4mI/edit#slide=id.g24535d0c6d4_0_178)

---

### Task B: "Textbooks Are All You Need" Case Study
#### Description:
- Implement the **"Textbooks Are All You Need"** case study using your own dataset.
- Follow the methodology from the original case study but adapt it for smaller data.

#### Requirements:
1. **Code Implementation:**
   - Full implementation in Colab, optimized for **Colab Pro A100 GPU setup**.
   - Use a smaller dataset for training.

2. **Artifacts:**
   - Provide all code, input data, outputs, and model checkpoints.

3. **Resources Utilized:**
   - Explain how **ChatGPT (GPT-4)** was used to assist with code implementation and debugging.

#### Resources:
- [YouTube Video](https://www.youtube.com/watch?v=gmFi6W8DPdM)
- [Textbook GitHub Repository](https://github.com/jina-ai/textbook)
- [Colab Notebook](https://colab.research.google.com/drive/1T4IfGfDJ8uxgU8XBPpMZivw_JThzdQim?usp=sharing)
- [Paper: "Textbooks Are All You Need"](https://arxiv.org/pdf/2306.11644.pdf)

---

## Deliverables

### Task A Deliverables:
- **Colab Notebook:** Modular implementation of NanoGPT.
- **Trained Model:** Model trained on a custom book dataset.
- **Medium Article:** Detailed explanation of the code and methodology.
- **Presentation:** A 10-minute presentation explaining the process.

### Task B Deliverables:
- **Colab Notebook:** Implementation of the "Textbooks Are All You Need" case study.
- **Artifacts:** All relevant input, output, and model checkpoints.
- **Documentation:** Explanations for methodology and use of GPT-4 for assistance.

